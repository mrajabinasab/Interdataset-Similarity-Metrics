{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application in Synthetic Data Evaluation\n",
    "\n",
    "In this notebook we illustrate how the new metrics can be applied to evaluate the quality of tabular synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pcametric import PCAMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating Table 1 from the paper\n",
    "In this section we show a basic example of the PCA metrics in action. We generate several synthetic datasets of varying quality (some engineered as adversarial examples) and compare the PCA metrics alongside regular metrics between them.\n",
    "\n",
    "We use the cardiotocography dataset from the [UCI repository](https://archive.ics.uci.edu/dataset/193/cardiotocography) as the base dataset (split randomly into train and test at 66%-33% ratio). Synthetic datasets are generated using several backends viz. [SynthCity](https://github.com/vanderschaarlab/synthcity), [CTGAN](https://github.com/sdv-dev/CTGAN), [DataSynthesizer](https://github.com/DataResponsibly/DataSynthesizer) and [Synthpop](https://www.synthpop.org.uk/get-started.html) in R. The quality of the synthetic datasets are determined using various common metrics implemented in the [SynthEval](https://github.com/schneiderkamplab/syntheval) library. The PCA metrics are then used to compare the quality of the synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_NAME = 'cardiotocography'\n",
    "\n",
    "df_train = pd.read_csv(f'datasets/{DATA_NAME}_train.csv')\n",
    "df_test = pd.read_csv(f'datasets/{DATA_NAME}_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.synthetic_data import add_noise_to_dataset, independent_sampling\n",
    "# code for generating the data are also available in the utils folder but we load csvs here for efficiency.\n",
    "\n",
    "df_noisy = add_noise_to_dataset(df_train, noise_level=0.1, threshold=5).round(1)\n",
    "\n",
    "df_indpt = independent_sampling(df_train)\n",
    "\n",
    "df_tvae_100 = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_tvae_100.csv').round(1)\n",
    "df_tvae_180 = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_tvae_180.csv').round(1)\n",
    "df_tvae_300 = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_tvae_300.csv').round(1)\n",
    "df_tvae_500 = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_tvae_500.csv').round(1)\n",
    "\n",
    "df_adsgan = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_adsgan.csv').round(1)\n",
    "df_bn = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_datasynthesizer.csv').round(1)\n",
    "df_cart = pd.read_csv(f'datasets/synthetic/{DATA_NAME}_synthpop.csv').round(1)\n",
    "\n",
    "df_best = df_test.sample(frac=0.8, random_state=42)\n",
    "df_val = df_test.drop(index=df_best.index)\n",
    "df_best.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SynthEval: inferred categorical columns...\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the synthetic data\n",
    "from syntheval import SynthEval\n",
    "\n",
    "metrics = {\n",
    "    \"pca\"       : {\"preprocess\": \"mean\"},\n",
    "    \"corr_diff\" : {\"mixed_corr\": True},\n",
    "    \"mi_diff\"   : {},\n",
    "    \"ks_test\"   : {\"sig_lvl\": 0.05, \"n_perms\": 1000},\n",
    "    \"hit_rate\"  : {\"thres_percent\": 0.05},\n",
    "    \"eps_risk\"  : {},\n",
    "    \"mia_risk\"  : {\"num_eval_iter\": 5}\n",
    "}\n",
    "\n",
    "SE = SynthEval(df_train, df_val, unique_threshold=10)\n",
    "res_df, rank_df = SE.benchmark({'noisy': df_noisy,\n",
    "                                'indpt': df_indpt,\n",
    "                                'tvae_100': df_tvae_100,\n",
    "                                'tvae_180': df_tvae_180,\n",
    "                                'tvae_300': df_tvae_300,\n",
    "                                'tvae_500': df_tvae_500,\n",
    "                                'adsgan': df_adsgan,\n",
    "                                'bn': df_bn,\n",
    "                                'cart': df_cart,\n",
    "                                'best': df_best}, analysis_target_var='Class', rank_strategy='summation', **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>noisy</th>\n",
       "      <th>indpt</th>\n",
       "      <th>tvae_100</th>\n",
       "      <th>tvae_180</th>\n",
       "      <th>tvae_300</th>\n",
       "      <th>tvae_500</th>\n",
       "      <th>adsgan</th>\n",
       "      <th>bn</th>\n",
       "      <th>cart</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pca_eigval_diff</th>\n",
       "      <th>value</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.452948</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>0.208126</td>\n",
       "      <td>0.06422</td>\n",
       "      <td>0.063852</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.003263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pca_eigvec_ang</th>\n",
       "      <th>value</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.350485</td>\n",
       "      <td>0.480847</td>\n",
       "      <td>0.340335</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.035344</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.004097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">corr_mat_diff</th>\n",
       "      <th>value</th>\n",
       "      <td>0.072219</td>\n",
       "      <td>6.905142</td>\n",
       "      <td>4.383363</td>\n",
       "      <td>3.378907</td>\n",
       "      <td>2.57978</td>\n",
       "      <td>2.235645</td>\n",
       "      <td>1.780792</td>\n",
       "      <td>2.643394</td>\n",
       "      <td>1.200779</td>\n",
       "      <td>0.978702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mutual_inf_diff</th>\n",
       "      <th>value</th>\n",
       "      <td>0.169436</td>\n",
       "      <td>2.733968</td>\n",
       "      <td>10.064334</td>\n",
       "      <td>5.396227</td>\n",
       "      <td>2.70753</td>\n",
       "      <td>2.183597</td>\n",
       "      <td>1.803873</td>\n",
       "      <td>1.553276</td>\n",
       "      <td>1.094276</td>\n",
       "      <td>1.982659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ks_tvd_stat</th>\n",
       "      <th>value</th>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.213303</td>\n",
       "      <td>0.144682</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.084122</td>\n",
       "      <td>0.082205</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.030964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.027761</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.015231</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">frac_ks_sigs</th>\n",
       "      <th>value</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">hit_rate</th>\n",
       "      <th>value</th>\n",
       "      <td>0.605132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">eps_identif_risk</th>\n",
       "      <th>value</th>\n",
       "      <td>0.972915</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.038489</td>\n",
       "      <td>0.059159</td>\n",
       "      <td>0.085531</td>\n",
       "      <td>0.039914</td>\n",
       "      <td>0.044191</td>\n",
       "      <td>0.232359</td>\n",
       "      <td>0.295795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mia_cls_risk</th>\n",
       "      <th>value</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.382583</td>\n",
       "      <td>0.432188</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.473408</td>\n",
       "      <td>0.447907</td>\n",
       "      <td>0.427974</td>\n",
       "      <td>0.524231</td>\n",
       "      <td>0.347626</td>\n",
       "      <td>0.355009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.016322</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.010657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <td>7.058627</td>\n",
       "      <td>7.777896</td>\n",
       "      <td>6.797352</td>\n",
       "      <td>6.786843</td>\n",
       "      <td>7.314105</td>\n",
       "      <td>7.415119</td>\n",
       "      <td>7.679329</td>\n",
       "      <td>7.894268</td>\n",
       "      <td>8.277978</td>\n",
       "      <td>8.206445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_rank</th>\n",
       "      <th></th>\n",
       "      <td>5.970007</td>\n",
       "      <td>5.164043</td>\n",
       "      <td>4.243083</td>\n",
       "      <td>4.292928</td>\n",
       "      <td>4.846672</td>\n",
       "      <td>4.948557</td>\n",
       "      <td>5.147218</td>\n",
       "      <td>5.46269</td>\n",
       "      <td>5.860101</td>\n",
       "      <td>5.873642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_rank</th>\n",
       "      <th></th>\n",
       "      <td>1.08862</td>\n",
       "      <td>2.613853</td>\n",
       "      <td>2.554269</td>\n",
       "      <td>2.493914</td>\n",
       "      <td>2.467433</td>\n",
       "      <td>2.466562</td>\n",
       "      <td>2.532112</td>\n",
       "      <td>2.431578</td>\n",
       "      <td>2.417877</td>\n",
       "      <td>2.332803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                    noisy     indpt   tvae_100  tvae_180  tvae_300  \\\n",
       "pca_eigval_diff  value  0.000002  0.452948   0.039835  0.208126   0.06422   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "pca_eigvec_ang   value  0.000008  0.350485   0.480847  0.340335  0.012754   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "corr_mat_diff    value  0.072219  6.905142   4.383363  3.378907   2.57978   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "mutual_inf_diff  value  0.169436  2.733968  10.064334  5.396227   2.70753   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "ks_tvd_stat      value  0.001821  0.017224   0.213303  0.144682  0.095739   \n",
       "                 error  0.001685  0.001771   0.027761  0.020624  0.011609   \n",
       "frac_ks_sigs     value  0.027778       0.0        1.0       1.0  0.972222   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "hit_rate         value  0.605132       0.0        0.0       0.0       0.0   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "eps_identif_risk value  0.972915  0.003564   0.013542  0.038489  0.059159   \n",
       "                 error       NaN       NaN        NaN       NaN       NaN   \n",
       "mia_cls_risk     value  0.333333  0.382583   0.432188  0.467597  0.473408   \n",
       "                 error       0.0  0.011971   0.017428  0.015831  0.014811   \n",
       "rank                    7.058627  7.777896   6.797352  6.786843  7.314105   \n",
       "u_rank                  5.970007  5.164043   4.243083  4.292928  4.846672   \n",
       "p_rank                   1.08862  2.613853   2.554269  2.493914  2.467433   \n",
       "\n",
       "dataset                 tvae_500    adsgan        bn      cart      best  \n",
       "pca_eigval_diff  value  0.063852  0.119112   0.00184  0.000222  0.003263  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "pca_eigvec_ang   value  0.035344  0.006887  0.003861  0.003029  0.004097  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "corr_mat_diff    value  2.235645  1.780792  2.643394  1.200779  0.978702  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "mutual_inf_diff  value  2.183597  1.803873  1.553276  1.094276  1.982659  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "ks_tvd_stat      value  0.084122  0.082205  0.080502  0.021894  0.030964  \n",
       "                 error  0.011684  0.015231  0.023369  0.002748  0.003333  \n",
       "frac_ks_sigs     value  0.861111  0.638889  0.444444  0.111111  0.083333  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "hit_rate         value       0.0       0.0       0.0  0.002138  0.016393  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "eps_identif_risk value  0.085531  0.039914  0.044191  0.232359  0.295795  \n",
       "                 error       NaN       NaN       NaN       NaN       NaN  \n",
       "mia_cls_risk     value  0.447907  0.427974  0.524231  0.347626  0.355009  \n",
       "                 error  0.012376  0.016096  0.016322  0.007011  0.010657  \n",
       "rank                    7.415119  7.679329  7.894268  8.277978  8.206445  \n",
       "u_rank                  4.948557  5.147218   5.46269  5.860101  5.873642  \n",
       "p_rank                  2.466562  2.532112  2.431578  2.417877  2.332803  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Table 1 in the paper ###\n",
    "res_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3\n",
    "Figure 3 is about the behavoiur of the PCA metrics during training of a generative autoencoder model. Due to licencing of the CTGAN code that we had to adjust slightly, we put the code for this in a separate notebook that is a fork of the original repository.\n",
    "\n",
    "[Link to Notebook in forked repository](https://github.com/notna07/ctgan-with-checkpoints/blob/main/gen_model_training_behaviour.ipynb)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"datasets/results/tvae_loss.png\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4\n",
    "Figure 4 is about checking the correlations between the PCA metrics and the regular metrics. \n",
    "\n",
    "The process and code for creating the correlation heatmap are part of a separate notebook. The blue annotations were added posthoc.\n",
    "\n",
    "[Link to Notebook in separate repository](https://github.com/schneiderkamplab/syntheval-model-benchmark-example/blob/main/metric_correlations.ipynb)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"datasets/results/corr_clust_result.png\" />\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
